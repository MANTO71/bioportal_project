{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook content\n",
    "\n",
    "Step by step\n",
    "- load data\n",
    "- extract text\n",
    "- store data ( paper id and text document) in data_dictionary\n",
    "\n",
    "Sintesis of the above things(final code v1)\n",
    "- load data\n",
    "- extract and store data\n",
    "- assert results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook content 1\n",
    "\n",
    "Api bioportal\n",
    "- api conection\n",
    "- query\n",
    "- results\n",
    "- query resources bioportal: all ontologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import urllib\n",
    "from urllib import parse, request\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Step by step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data.\n",
    "For this build path for every file in directory. paths store in a list. from the list of paths each file is read.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_json = []\n",
    "for root, dirs, files in os.walk('kaggle/document_parses/pdf_json/'): #Case:files under  ../../pdf_json directory\n",
    "    for file in files:\n",
    "        pdf_json.append(os.path.join(root, file)) #build a path for each file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pdf_json # list of paths "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract data firts record:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pdf_json[0]) as json_data:\n",
    "    data = json.load(json_data)\n",
    "\n",
    "data.keys() # metadata record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['metadata']['title']\n",
    "\n",
    "data['metadata']['title'] # title record. firt record not have a title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# data['abstract']\n",
    "\n",
    "data['abstract'] #neested data structure: list thar have inside dictionaries. each dictionary is a paragraph.\n",
    "\n",
    "content_abstract = ''\n",
    "for paragraph in data['abstract']:\n",
    "    content_abstract += paragraph['text']\n",
    "\n",
    "data=content_abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['body_text']\n",
    "\n",
    "data['body_text'] #neested data structure again: list that have inside dictionaries. each dictionary is a paragraph.\n",
    "\n",
    "len(data['body_text']) # have 37 paragrphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_body = ''\n",
    "for paragraph in data['body_text']:\n",
    "    content_body += paragraph['text']\n",
    "\n",
    "content_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### document_text = content_abstract + content_body\n",
    "\n",
    "document_text =  data['metadata']['title'] + content_abstract + content_body # total content firts record\n",
    "\n",
    "print(document_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Store data in a data dictionary(schema db proposal)\n",
    "\n",
    "data_dict = {'paper_id':[], 'documents_texts':[], 'bioportal_anotations':[]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load paper id y document en el data_dict para el primer registro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict['paper_id'].append(data['paper_id'])\n",
    "data_dict['documents_texts'].append(document_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sintesis of the above things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#v.1.1 load and store text data to anotate\n",
    "\n",
    "path_data = []\n",
    "for root, dirs, files in os.walk('kaggle/document_parses/'): \n",
    "    for file in files:\n",
    "        path_data.append(os.path.join(root,file))\n",
    "\n",
    "#extract content of the all records. load into data_dictionari\n",
    "data_dict = {'paper_idx':[], 'paper_id':[],'title':[],\n",
    "             'content_to_annotate':[], 'document_text':[],\n",
    "             'bioportal_anotations':[]}\n",
    "\n",
    "idx = 0\n",
    "for path in path_data:\n",
    "    \n",
    "    with open(path, 'r') as json_data:\n",
    "        data = json.load(json_data)\n",
    "        \n",
    "    \n",
    "    try:              #for pdf_json\n",
    "        content_abstract = ''\n",
    "        for paragraph in data['abstract']:\n",
    "            content_abstract += ' ' + paragraph['text']\n",
    "            \n",
    "        \n",
    "        content_body = ''\n",
    "        for paragraph in data['body_text']:\n",
    "            content_body += ' ' + paragraph['text']\n",
    "        \n",
    "        document_text = data['metadata']['title'] + content_abstract + content_body \n",
    "        \n",
    "        content_to_annotate = data['metadata']['title'] + ' ' + content_abstract\n",
    "\n",
    "                    \n",
    "    except KeyError:    # for pmc_json\n",
    "        \n",
    "        content_to_annotate= data['metadata']['title'] + ' ' + data['body_text'][0]['text']\n",
    "        content_body = ''\n",
    "        for paragraph in data['body_text']:\n",
    "            content_body += ' ' + paragraph['text']\n",
    "\n",
    "        document_text = data['metadata']['title'] + content_body\n",
    "    \n",
    "    data_dict['paper_idx'].append(idx)\n",
    "    data_dict['paper_id'].append(data['paper_id'])        \n",
    "    data_dict['title'].append(data['metadata']['title'])\n",
    "    data_dict['content_to_annotate'].append(content_to_annotate)\n",
    "    data_dict['document_text'].append(document_text)\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function load text in data dict v.1\n",
    "def load_text_for_paper_in_directory(path_to_directory):\n",
    "    '''v.1.1 load and store text data to anotate\n",
    "    \n",
    "    args:\n",
    "    process:\n",
    "    output:\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    global path_data\n",
    "    path_data = []\n",
    "    for root, dirs, files in os.walk(path_to_directory): \n",
    "        for file in files:\n",
    "            path_data.append(os.path.join(root,file))\n",
    "\n",
    "    #extract content of the all records. load into data_dictionari\n",
    "    global data_dict\n",
    "    data_dict = {'paper_idx':[], 'paper_id':[],'title':[],\n",
    "                 'content_to_annotate':[], 'document_text':[],\n",
    "                 'bioportal_anotations':[]}\n",
    "\n",
    "    idx = 0\n",
    "    for path in path_data:\n",
    "        \n",
    "        with open(path, 'r') as json_data:\n",
    "            data = json.load(json_data)\n",
    "\n",
    "        try:              #for pdf_json\n",
    "            content_abstract = ''\n",
    "            for paragraph in data['abstract']:\n",
    "                content_abstract += ' ' + paragraph['text']\n",
    "\n",
    "\n",
    "            content_body = ''\n",
    "            for paragraph in data['body_text']:\n",
    "                content_body += ' ' + paragraph['text']\n",
    "\n",
    "            document_text = data['metadata']['title'] + content_abstract + content_body \n",
    "\n",
    "            content_to_annotate = data['metadata']['title'] + ' ' + content_abstract\n",
    "\n",
    "\n",
    "        except KeyError:    # for pmc_json\n",
    "\n",
    "            content_to_annotate= data['metadata']['title'] + ' ' + data['body_text'][0]['text']\n",
    "            content_body = ''\n",
    "            for paragraph in data['body_text']:\n",
    "                content_body += ' ' + paragraph['text']\n",
    "\n",
    "            document_text = data['metadata']['title'] + content_body\n",
    "\n",
    "        data_dict['paper_idx'].append(idx)\n",
    "        data_dict['paper_id'].append(data['paper_id'])        \n",
    "        data_dict['title'].append(data['metadata']['title'])\n",
    "        data_dict['content_to_annotate'].append(content_to_annotate)\n",
    "        data_dict['document_text'].append(document_text)\n",
    "        idx += 1\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if the ejecution of this line not raise anything, every its good \n",
    "assert len(path_data) == len(data_dict['paper_id']) and len(path_data) == len(data_dict['document_text']), 'wrong'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bioportal apy query "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "REST_URL = \"http://data.bioontology.org\"\n",
    "API_KEY = \"3b00793b-f3cc-489c-9d6e-7a888f4b656e\"\n",
    "ontologies = \"ontology1,ontology2,...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "### list of ontologies bioportal\n",
    "\n",
    "def get_json(url):\n",
    "    opener = urllib.request.build_opener()\n",
    "    opener.addheaders = [('Authorization', 'apikey token=' + API_KEY)]\n",
    "    return json.loads(opener.open(url).read())\n",
    "\n",
    "resources = get_json(REST_URL + \"/\")\n",
    "\n",
    "ontologies = get_json(resources[\"links\"][\"ontologies\"])\n",
    "\n",
    "ontology_output = []\n",
    "for ontology in ontologies:\n",
    "    ontology_output.append(f\"{ontology['name']}\\n{ontology['@id']}\\n\")\n",
    "\n",
    "#for ont in ontology_output:\n",
    "    #print(ont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Ontologies selected\n",
    "\n",
    "ont_sel = pd.read_csv('select_onts.csv')\n",
    "\n",
    "list_onto = [x.replace('\\t','').replace(' ','').replace('\\n','') for x in list(ont_sel['Ontology'].values) if type(x)!=float]\n",
    "\n",
    "list_uniq = []\n",
    "for i in list_onto:\n",
    "    if i not in list_uniq:\n",
    "        list_uniq.append(i)\n",
    "    else:\n",
    "        next\n",
    "\n",
    "#list_uniq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge ontologies bioportal with ontologies selected\n",
    "ontologies = ' ' \n",
    "for onto in ontology_output:\n",
    "    \n",
    "    for i in list_uniq:\n",
    "        \n",
    "        if onto.find(i)>0:\n",
    "            if ontologies.find(i) > 0:\n",
    "                next\n",
    "            else:\n",
    "                ontologies += i + ' '     \n",
    "ontologies = ontologies[1:-1].replace(' ',',') #param query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make url query function\n",
    "def make_url_query(API_KEY,\n",
    "                   ontologies, \n",
    "                   expand_class_hierachy_text,\n",
    "                   class_hierachy_max_level, text):\n",
    "    global url\n",
    "    url = REST_URL+ \"\"\"/annotator/?apikey={}&ontologies={}&expand_class_hierachy={}&class_hierachy_max_level={}&text={}\"\"\".format(API_KEY, ontologies,\n",
    "                                          expand_class_hierachy_text,class_hierachy_max_level,text)\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#v.1 api calls\n",
    "def make_query_bioportal_api(index_data_dict, \n",
    "                             API_KEY,\n",
    "                             ontologies,\n",
    "                             expand_class_hierachy_text,\n",
    "                             class_hierachy_max_level):\n",
    "    \n",
    "    for i in index_data_dict:                    #data_dict['paper_idx']:\n",
    "            \n",
    "        #text to anotate extract from data_dict\n",
    "        text = parse.quote(data_dict['content_to_annotate'][i])\n",
    "        #make url\n",
    "            \n",
    "        make_url_query(API_KEY, ontologies, expand_class_hierachy_text, class_hierachy_max_level, text)\n",
    "        #call api\n",
    "        api_call = request.urlopen(url)\n",
    "        annotations = json.loads(api_call.read().decode('utf-8'))\n",
    "\n",
    "        #store anotations\n",
    "        data_dict['bioportal_anotations'].append(annotations)\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'paper_idx': [],\n",
       " 'paper_id': [],\n",
       " 'title': [],\n",
       " 'content_to_annotate': [],\n",
       " 'document_text': [],\n",
       " 'bioportal_anotations': []}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_query_bioportal_api(data_dict['paper_idx'][:4], API_KEY, ontologies, 'true',3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
