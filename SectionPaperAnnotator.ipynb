{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import urllib\n",
    "import pandas as pd\n",
    "from urllib import parse, request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REST_URL = \"http://data.bioontology.org\"\n",
    "API_KEY = '3b00793b-f3cc-489c-9d6e-7a888f4b656e'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_directory(path_to_directory):\n",
    "    '''documentation here'''\n",
    "    global path_files\n",
    "    path_files = []\n",
    "\n",
    "    for root, dirs, files in os.walk(path_to_directory):\n",
    "        for file in files:\n",
    "            path_files.append(os.path.join(root, file))\n",
    "\n",
    "    return path_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_directory('data/kaggle/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selec_ontologies(path_to_select_ontologies):\n",
    "    '''read file which contains a list of ontlogies selected by researchers'''\n",
    "    \n",
    "    ont_sel = pd.read_csv('data/ont_select.csv')\n",
    "\n",
    "    list_onto = [x.replace('\\t','').replace(' ','').replace('\\n','') for x in list(ont_sel['Ontology'].values)if type(x)!=float]\n",
    "    \n",
    "    global onto_select\n",
    "    onto_select= []\n",
    "    \n",
    "    for i in list_onto:\n",
    "        \n",
    "        if i not in onto_select:\n",
    "            onto_select.append(i)\n",
    "        else:\n",
    "            next\n",
    "            \n",
    "        return onto_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_ontologies('data/ont_select.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_json(url):\n",
    "    opener = urllib.request.build_opener()\n",
    "    opener.addheaders = [('Authorization', 'apikey token=' + API_KEY)]\n",
    "    return json.loads(opener.open(url).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bio_onts():\n",
    "    '''retrieve all ontologies stored in bioportal'''\n",
    "    \n",
    "    resources = get_json(REST_URL + \"/\")\n",
    "    ontologies = get_json(resources[\"links\"][\"ontologies\"])\n",
    "    \n",
    "    global onto_bio\n",
    "    onto_bio = []\n",
    "    for ontology in ontologies:\n",
    "        onto_bio.append(f\"{ontology['name']}\\n{ontology['@id']}\\n\")\n",
    "        \n",
    "    return onto_bio    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bio_onts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ontologies():\n",
    "    '''merge ontologies selected and ontologies from bio portal'''\n",
    "    \n",
    "    onto_bio = bio_onts()\n",
    "    onto_select = select_ontologies('data/ont_select.csv')\n",
    "    \n",
    "    \n",
    "    global ontologies\n",
    "    ontologies = '' \n",
    "    \n",
    "    for ontosel in onto_select:\n",
    "        for ontobio in onto_bio:\n",
    "            if ontobio.find(ontosel)>1:\n",
    "                if not ontologies.find(ontosel)>1:\n",
    "                    ontologies += ontosel +' '\n",
    "                else:\n",
    "                    next\n",
    "    ontologies = ontologies[:-1].replace(' ',',')\n",
    "    \n",
    "    return ontologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ontologies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_url_query(API_KEY,\n",
    "                   ontologies, \n",
    "                   expand_class_hierachy_text,\n",
    "                   class_hierachy_max_level, text):\n",
    "    global url\n",
    "    url = REST_URL+ \"\"\"/annotator/?apikey={}&ontologies={}&expand_class_hierachy={}&class_hierachy_max_level={}&text={}\"\"\".format(API_KEY, ontologies,\n",
    "                                          expand_class_hierachy_text,class_hierachy_max_level,text)\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_api_to_annotate(text_to_annotate):\n",
    "    '''documentation here'''\n",
    "    \n",
    "    expand_class_hierachy='true'\n",
    "    class_hierachy_max_level=3\n",
    "    \n",
    "    url= make_url_query(API_KEY, ontologies, expand_class_hierachy, class_hierachy_max_level, parse.quote(text_to_annotate))\n",
    "    api_call = request.urlopen(url)\n",
    "    global annotations\n",
    "    annotations = json.loads(api_call.read().decode('utf-8'))\n",
    "    return annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class annotationsdb:\n",
    "    '''\n",
    "    this class store data for each record annotated;\n",
    "    public variable: dbDict which contain data;\n",
    "    private variable: none;\n",
    "    methods: - for update dict values;\n",
    "             - for store data in to json file;\n",
    "    '''\n",
    "    \n",
    "    db = {'paper_idx':[],'paper_id':[], 'title':[], 'annotations':[]}\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "          \n",
    "    def updateValues(valueIdx, valueId, valueTitle, valueAnnotations):\n",
    "        annotationsdb.db['paper_idx'].append(valueIdx)\n",
    "        annotationsdb.db['paper_id'].append(valueId)\n",
    "        annotationsdb.db['title'].append(valueTitle)\n",
    "        annotationsdb.db['annotations'].append(valueAnnotations)\n",
    "        \n",
    "        if len(annotationsdb.db['annotations']):\n",
    "            return 'update OK'\n",
    "        \n",
    "    def storeData(self):\n",
    "        with open('annotatedPapersDB.json','w') as file_handler:\n",
    "            json.dump(db, file_handler)\n",
    "            \n",
    "    def __str__():\n",
    "        print(annotationsdb.db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam_r1=paths[0]  # pmc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam_r2=paths[48] #pdf_json\n",
    "sam_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_paths = [sam_r1,sam_r2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(sam_r1,'r') as json_handler:\n",
    "    data1 = json.load(json_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['paper_id']            ####pmc\n",
    "#data['metadata']['title']\n",
    "#data['body_text'] list of paragraphs\n",
    "#data1['body_text'][17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(sam_r2,'r') as json_handler:\n",
    "    data2 = json.load(json_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data2['body_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['paper_id']            #### pdf_json\n",
    "#data['metadata']['title']\n",
    "#data['abstract'] list of paragraps \n",
    "#data['body_text'] list of paragraps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  sintesis of above things: case to papers: one pmc one pdf_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "idx = 0\n",
    "for path in list_paths:\n",
    "    \n",
    "    list_annotations = []\n",
    "    \n",
    "    with open(path,'r') as json_handler:\n",
    "        data = json.load(json_handler)\n",
    "        \n",
    "    try: \n",
    "        for paragraph in data['abstract']:\n",
    "            text_to_annotate = paragraph['text']\n",
    "            \n",
    "            annotations = call_api_to_annotate(text_to_annotate)\n",
    "            print(len(annotations))\n",
    "            if annotations:\n",
    "                for annotation in anottations:\n",
    "                    list_annotations.append(annotation)\n",
    "            else:\n",
    "                pass\n",
    "                 \n",
    "        \n",
    "        for paragraph in data['body_text']:\n",
    "            tex_to_annotate = paragraph['text']\n",
    "            \n",
    "            annotations = call_api_to_annotate(tex_to_annotate)\n",
    "            \n",
    "            print(len(annotations))\n",
    "            if annotation:\n",
    "                for annotation in annotations:\n",
    "                    list_anotations.append(annotation)\n",
    "                else:\n",
    "                    pass\n",
    "            \n",
    "    except:\n",
    "        p = 0\n",
    "        for paragraph in data['body_text']:\n",
    "            text_to_annotate = paragraph['text']\n",
    "            \n",
    "            if text_to_annotate:\n",
    "            \n",
    "                annotations = call_api_to_annotate(text_to_annotate)\n",
    "                print(len(annotations))\n",
    "\n",
    "                if annotations:\n",
    "                    for annotation in annotations:\n",
    "\n",
    "                        list_annotations.append(annotation)\n",
    "                else: \n",
    "                    pass  \n",
    "            else:\n",
    "                pass\n",
    "            p +=1\n",
    "                \n",
    "    finally:\n",
    "        #store annotations in list anotations\n",
    "        text_to_annotate = data['metadata']['title']\n",
    "        \n",
    "        #call api\n",
    "        annotations = call_api_to_annotate(text_to_annotate)\n",
    "        print(len(annotations))\n",
    "        print('finally')\n",
    "        for annotation in annotations:\n",
    "            list_annotations.append(annotation)\n",
    "            \n",
    "    annotationsdb.updateValues(idx, data['paper_id'], data['metadata']['title'], list_annotations)\n",
    "    idx +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "382+127+296+228+43+212+65+74+637+255+310+864+185+419+99+168+33+62"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(annotationsdb.db['annotations'][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
